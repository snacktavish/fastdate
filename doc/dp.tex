% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{amsmath}
\usepackage{amssymb}

\newcounter{instr}
\newcommand{\ninstr}{\refstepcounter{instr}\theinstr.}

\newcommand{\ejmcomment}[1]{{\color{green} #1}}
\usepackage{hyperref}
\hypersetup{backref,  linkcolor=blue, citecolor=red, colorlinks=true, hyperindex=true}

\begin{document}

\title{A dynamic programming approach for speed-dating}

\titlerunning{Speed dating}

\author{Tom\'{a}\v{s} Flouri1\inst{1}}
\authorrunning{Tom\'{a}\v{s} Flouri et al.} % abbreviated author list
\institute{Heidelberg Institute of Theoretical Studies\\
\email{Tomas.Flouri@h-its.org}}

\maketitle

\begin{abstract}
An explanation of the dynamic programming algorithm used in \cite{Akerborg2008}.
\end{abstract}

\section{Preliminaries}

\subsection{Basic definitions}

A tree $T=(V,E)$ is a connected acyclic graph where $V$ is the set of {\em
nodes} and $E$ the set of {\em edges}, such that $E = V\times V$. We use the
notation $(u,v) \in E$ to denote an edge with end-points $u,v \in V$. If $T$ is
{\em oriented}, then {\em in-degree} (resp. {\em out-degree}) of a node denotes
the number of incoming (resp. outgoing edges) of $u$. In the opposite case, the
{\em degree} of node $u$ denotes the number of edges $u$ is an end-point of.
Further, we denote with $T_u$ the subtree of $T$ rooted at node $u$.  A {\em
rooted binary tree} $T$ is a {\em directed} tree with all nodes having
in-degree 1 and out-degree 1 ({\em inner} nodes), or in-degree 1 and out-degree
0 ({\em leaves}). Furthermore, one node has in-degree 0 and out-degree 2 ({\em
root}).  In the rest of the text we implicitely assume under the term tree a
binary rooted tree.  We denote the set of leaves of tree $T$ as $L(T)$.  The
cardinality of a set $X$ is denoted as $|X|$. The {\em height} $h(u)$ of a node
$u$ of $T$ is defined as 
%
\[ h(u) = \left\{ \begin{array}{ll}
\max(h(v), h(w)) + 1 & \quad : \quad u \notin L(T)\\
1                    & \quad : \quad u    \in L(T)\\
\end{array}\right. \] 
The height $h(T)$ of a tree $T$ is the height of its root.: Finally, we will
implicitely use the notation $r$ for specifying the root of a tree, and
$\ell_{u,v}$ for the length of edge $(u,v)$.

\subsection{Gamma function, Gamma distribution}

The {\em Gamma function} is an extension to the factorial function to handle
any real or complex number as argument. For point $t$ it is defined as
$$\Gamma(t) = \int_0^\infty x^{t-1} e^{-x} dx.$$

The {\em probability density function} in the shape-rate parameterization of a
{\em gamma distribution} given the {\em mean} $\bar{r}$ and variance $\sigma$ is
$$ g(x;\alpha,\beta) = \frac{\beta^{\alpha}x^{a-1}e^{-x\beta}}{\Gamma(\alpha)} $$

where $\beta = \bar{r} / \sigma$ and $\alpha = \bar{r} \beta$.
\ejmcomment{I re-labeled this with $\bar{r}$ for the mean of the gamma prior to avoid confusion with $\mu$ for birth rate.}

Its natural logarithm can be computed as
$$ \ln g(x;\alpha,\beta) = \alpha\ln\beta + (\alpha-1)\ln x -x\beta - \ln\Gamma(\alpha) $$

\section{Dynamic programming algorithm}

We are given an integer $N \geq h(T)$ which we use to construct a grid of lines
over the height of a tree (numbered 1 to $N$), such that the (uniform) distance between any two
adjacent lines is $h(T) / N$.  Our goal is to project each node of $T$ onto one
of the $N$ using a mapping $\phi : V \mapsto \{1,\ldots,N\}$ such that the
following properties are maintained.
\begin{enumerate}
\item $\forall u,v,w \in V : (u,v), (u,w) \in E \Rightarrow \phi(u) > \phi(v) \wedge \phi(u) > \phi(w)$,
\item $\phi(u) = 1, \forall u \in L(T)$,
\item $\phi(r) = N$
\end{enumerate}

Property 1 ensures that no node $v$ in the subtree rooted at $u$ is placed on
line $\phi(v) \geq \phi(u)$. Property 2 maps all leaves to the first line (line 1).
Property 3 maps the root to the highest line (line $N$).

The mapping is computed by maximizing a function, which defines a
dynamic programming algorithm.  We briefly explain the algorithm informally.

The DP uses a post-order traversal of the target tree. For each node $u$, it
computes the maximal value $f(u,t)$ for each line $t$ that node $u$ is allowed to be
placed on, along with all the lines that its two children are allowed to placed
on. This maximal value is then stored in a table along with the positions (lines) its
two children were placed on. 

We first need to set the interval of lines (discretizations) that a specific
node can be placed on.  This interval (denoted $d(u)$) for node $u$ is defined
as $$ d(u) = \{ x\ |\  h(u) \leq x \leq N - (h(r) - h(u))\}.$$  This is
justified by the fact that the farthest {\em path} leading from node $u$ to a
leaf is of size $h(u)$ and contains exactly $h(u)$ nodes including $v$.
Therefore, even if all nodes in the distinct height in the subtree rooted at
$u$ are placed on distinct discretization, the lowest line that $u$ can be
placed on is line $h(u)$.

Next, we define the maximization function $f$ that is computed for each node $u \in
V\setminus L(T)$ and for each discretization line $t_u$:  
$$ f(u,t_u) = b(t_u,|L(T_u)|) \ln g(\ell_{u,v} / (t_u - t_v)) \ln g(\ell_{u,w} / (t_u -
t_w)) f(v,t_v) f(w,t_w) $$ where $t_u \in d(u)$, $t_v \in d(v)$, $t_w \in
d(w)$ and $b(t_u,|L(T_u)|)$ is the birth-death process function {\bf TODO:
finish description} which is based on the placement of $u$ and the number of
leaves the subtree rooted at $u$ has.
Fig.~\ref{fig:dp} describes the algorithm in detail.


\setcounter{instr}{0}
\begin{figure}[t]
\begin{center}
\begin{tabular}{|rl|}
\hline
\multicolumn{2}{|l|}{\textsc{DP}$(T, N, u)$}\\
\ninstr & $v \leftarrow$ left child of $u$\\
\ninstr & $w \leftarrow$ right child of $u$\\
\ninstr & \textbf{if} $v \in L(T)$ \textbf{then}\\
\ninstr & \qquad $M(v,1) \leftarrow 1$\\
\ninstr & \qquad \textbf{return}\\
\ninstr & \textsc{DP}(T,N,v)\\        
\ninstr & \textbf{if} $w \in L(T)$ \textbf{then}\\
\ninstr & \qquad $M(w,1) \leftarrow 1$\\
\ninstr & \qquad \textbf{return}\\
\ninstr & \textsc{DP}(T,N,w)\\        
\ninstr & \textbf{for} $t_u \leftarrow \min d(u)$ \textbf{to} $\max d(u)$ \\
\ninstr & \qquad $\hat{f}_u \leftarrow 0, \hat{t}_v \leftarrow 0, \hat{t}_w \leftarrow 0$\\
\ninstr & \qquad \textbf{for} $t_v \leftarrow \min d(v)$ \textbf{to} $\min\{\max d(v), t_u\}$ \\
\ninstr & \qquad \qquad \textbf{for} $t_w \leftarrow d(w)$ \textbf{to} $\min\{\max d(w), t_u\}$ \\
\ninstr & \qquad \qquad \qquad $r_{u,v} \leftarrow \ell_{u,v}/(t_u - t_v)$ \\
\ninstr & \qquad \qquad \qquad $r_{u,w} \leftarrow \ell_{u,w}/(t_u - t_w)$ \\
\ninstr & \qquad \qquad \qquad $f(u,t_u) \leftarrow b(t_u,|L(T_u)|) \ln g(r_{u,v}) \ln g(r_{u,w}) f(v,t_v) f(w,t_w)$\\
\ninstr & \qquad \qquad \qquad \textbf{if} $f(u,t_u) > \hat{f}_u$ \textbf{then} \\
\ninstr & \qquad \qquad \qquad \qquad $\hat{f}_u \leftarrow f(u,t_u), \hat{t}_v \leftarrow t_v, \hat{t}_w \leftarrow t_w$\\
\ninstr & \qquad $M(u,t_u) \leftarrow \hat{f}_u, M^l(u,t_u) \leftarrow \hat{t}_v, M^r(u,t_u) \leftarrow \hat{t}_w$  \\
\hline  
\end{tabular}
\end{center}
\caption{The DP algorithm for computing relative divergence times. The
algorithm starts by passing the tree ($T$), number of discretization lines
(($N$) and the root of $T$ ($u$). It recursively traverses the tree in
postorder and thne computes the best placement for every node $u$.}
\label{fig:dp}
\end{figure}


\section{Sampled Birth Death from Stadler 2010 \cite{Stadler2010}}


\begin{enumerate}
\item[$\lambda$]  is the per lineage birth (speciation) rate
\item[$\mu$]  is the per lineage death (extinction) rate
\item[$\psi$]  is the per lineage rate of sampling in the past (e.g. fossils) (in same units as $\lambda$ and $\mu$).
\item[$\rho$ ] is the proportion of total extant descendents $N$ which are sampled $n$.
\item[$n$] is the number of extant (current) sampled descendents of a node.
\item[$m$] is the number of extinct (fossil) sampled descendents of a node.
\item[$c_1,c_2$]  are useful constants.
$$c_1 = |\sqrt{(\lambda-\mu-\psi)^2 + 4\lambda\psi}|$$
$$c_2 = \frac{\lambda-\mu-2\lambda\rho-\psi}{c_1}$$
\item[$\hat{c_1},\hat{c_2}$]  are $c_1,c_2$ when $\psi=0$
$$\hat{c_1}=c_1(\psi=0) = |\sqrt{(\lambda-\mu)^2}|$$
$$\hat{c_2}=c_2(\psi=0) = \frac{\lambda-\mu-2\lambda\rho}{\hat{c_1}}$$
\item[$p_0(t)$]  is the probability that an individual alive at time $t$ before today has no sampled descendents (extinct or extant).
$$p_0(t) = \frac{\lambda+\mu+\psi+c_1\frac{e^{-c_1t}(1-c_2)-(1+c_2)}{e^{-c_1t}(1-c_2)+(1+c_2)}}{2\lambda}$$
\item[$p_1(t)$]  is the probability that an individual alive at time $t$ before today has precisely 1 sampled extant descendents and no sampled extinct descendents.
$${p_1}(t) = \frac{4\rho}{2(1-c_2^2)+e^{-c_1t}(1-c_2)^2+e^{c_1t}(1+c_2)^2}$$
\item[$\hat{p_1}(t)$]  is the probability that an individual alive at time $t$ before today has precisely 1 sampled extant descendents. When no extinct taxa have been sampled $\psi = 0$.
$$\hat{p_1}(t) = p_1(t|\psi=0)$$
$$\hat{p_1}(t) = \frac{4\rho}{2(1-\hat{c_2}^2)+e^{-\hat{c_1}t}(1-\hat{c_2})^2+e^{\hat{c_1}t}(1+\hat{c_2})^2}$$
\item[$x_1$]  is the node time of interest ($t_{mrca}=x_1$).
\item[$x_i$]  is the estimated node time for each child node (there are $n+m-1$).

\end{enumerate}


\subsubsection{Corollary 3.9} The probability density of a sampled tree $T$ with $n>1$ extant sampled leaves, $m\geq0$ extinct sampled leaves and $k\geq0$ sampled individuals with sampled descendents, 
conditioned on the time of the mrca being $x_1$. \ejmcomment{EJM needs to re-check against Stadler 2010}

$$f[T|t_{mrca}=x_1,n] = \frac{\lambda^{n+m+2}\psi^{k+m}}{(n-1)\hat{p_1}(x_1)^2}\left(\frac{\lambda\rho+(\lambda(1-\rho)-\mu)e^{-(\lambda-\mu)x_1}}{\rho\lambda(1-e^{-(\lambda-\mu)x_1})}\right)^{n-2}
p_1(x_1)\prod_{i=1}^{n+m-1}p_1(x_i)\prod_{i=1}^{m}\frac{p_0(y_i)}{p_1(y_i)}$$


with no sampled fossils ($\psi=0$, $m=0$) this simplifies to:
$$f[T|t_{mrca}=x_1,n] = \frac{\lambda^{n+2}}{(n-1)\hat{p_1}(x_1)^2}\left(\frac{\lambda\rho+(\lambda(1-\rho)-\mu)e^{-(\lambda-\mu)x_1}}{\rho\lambda(1-e^{-(\lambda-\mu)x_1})}\right)^{n-2}
\hat{p_1}(x_1)\prod_{i=1}^{n-1}\hat{p_1}(x_i)$$

\textbf{This is what we should use for  $b(t_u, n)$ in the DP algorithm with no fossils.}\\
Requires node times for all nodes in subtree $x_1 ... x_n-1$.\\
\ejmcomment{Do we keep those? I'm not clear on how to incorporate this into the DP algorithm}

\subsubsection{Theorem 3.11} The probability density of a sampled tree $T$ with $n$ extant sampled leaves, $m$ extinct sampled leaves, $n+m>0$, and $k\geq0$ sampled individuals with sampled descendents, 
conditioned on the time of the mrca being $x_1$. \ejmcomment{EJM needs to re-check against Stadler 2010}

$$f[T|t_{mrca}=x_1,n,m] = \frac{4n\rho\lambda\psi^{k+m}}{c_1(c_2+1)(1-c_2+(1+c_2)e^{c_1x_1})}\prod_{i=1}^{n+m-1}\lambda p_1(x_i)\prod_{i=1}^{m}\frac{p_0(y_i)}{p_1(y_i)}$$

\subsubsection{BD process from Kendall 1949 from Gernhard 2008\\}

$p_0(t)=\frac{\mu(1-e^{-(\lambda-\mu)t}}{\lambda-\mu e^{-(\lambda-\mu)t}}$\\
$p_1(t)=\frac{(\lambda-u)^2e^{-(\lambda-\mu)t}}{(\lambda-\mu e^{-(\lambda-\mu)t})^2}$\\
$p_n(t)=(\frac{\lambda}{\mu})^2p_1(t)(p_0(t))^{n-1}$\\
$p_n(t)=(\frac{\lambda}{\mu})^2\frac{(\lambda-\mu)^2e^{-(\lambda-\mu)t}}{(\lambda-\mu e^{-(\lambda-\mu)t})^2}(\frac{\mu(1-e^{-(\lambda-\mu)t}}{\lambda-\mu e^{-(\lambda-\mu)t}})^{n-1}$\\
%$log(p_n(t))= 2(log(\lambda)-log(\mu)$

\subsubsection{BD process from Prime GSR\\}

dbdiff $= \mu - \lambda$\\
$u_t =\frac{\lambda-(1-e^{-(\lambda-\mu)t})}{\lambda-(\mu e^{-(\lambda - \mu)t})}$ From calcPt\_Ut, in the case that $\lambda != \mu$. \ejmcomment{$t$ may or may not always be 1 in $u_t$?}\\
$P_t = \frac{-(\lambda-\mu)}{\lambda-(\mu e^{-(\lambda - \mu)t})}$ from partialEdgeTimeProb\\
$E=e^{-(\lambda-\mu)t}$\\
factor $= (n-1)\frac{\lambda}{u_t}$ from partialEdgeTimeProb, because BDvar[y]=$u_t$ from calcBirthDeathProbs\_recursive. 
\ejmcomment{is this in order to scale the relative time probabilities to the assumption that the root is at $t=1$?}\\
partialEdgeTimeProb = factor $*P_t^2 *E$\\
partialEdgeTimeProb = $(n-1)\frac{\lambda}{u_t} * ( \frac{-(\lambda-\mu)}{\lambda-(\mu e^{-(\lambda - \mu)t})})^2 * e^{-(\lambda-\mu)t}$\ejmcomment{But I'm not sure which of these are logged already...}\\

\subsection{Corrrelated rates \cite{Kishino2001}}\ejmcomment{This section is still just notes}
Treats each node as having a rate.
The rate for each edge is the mean of the rates at the two nodes.
Given log  of the rate at the beginning of the branch $u$, the log of the rate at the end of the branch $v$ should be normally distributed with a mean of that value.
Variance, $\sigma$, is the branch length $l$ (in substitutions per site NOT TIME) multiplied by some parameter $\nu$
$\nu$ determines the extent of rate-autocorrelation. High $\nu$ implies low autocorrelation. 

Force one branch from root to have no change.


Would be easy to implement in DP using:\\
Consider the rate at a node $u$ to be the rate for the edge from $p$ (the parent of $u$) to $u$.\\
Correlated gamma rates prior, $g_c(r)$, requires altering $\bar{r}$ of the prior for the rates $r_{u,v}, r_{u,w}$.\\
For $r_{u,v}$ and $r_{u,w}$, mean of $g_c(r)$, $\bar{r}$ = $r_{p,u}$.\\
\cite{Kishino2001} use log-normal distributions.\\



\bibliographystyle{splncs03}
\bibliography{dating}
\end{document}
